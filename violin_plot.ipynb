{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63caeed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.interpolate\n",
    "import astropy.table\n",
    "import numpy\n",
    "import time\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import numpy.random as random\n",
    "import statistics\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b45b8c",
   "metadata": {},
   "source": [
    "# Evolutionary Track Interpolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c533b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pms_data(tracks=\"BHAC15\"):\n",
    "\n",
    "    # Load in the data for the appropriate set of evolutionary tracks.\n",
    "\n",
    "    path = './data/evolutionary_tracks/'\n",
    "    \n",
    "    if tracks == \"BHAC15\":\n",
    "        f = open(path+\"BHAC15_tracks+structure.txt\",\"r\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        colnames = lines[46].split()[1:]\n",
    "\n",
    "        data = numpy.loadtxt(path+\"BHAC15_tracks+structure.txt\", comments=\"!\", \\\n",
    "                skiprows=45)\n",
    "    elif tracks == \"Siess2000\":\n",
    "        f = open(path+\"siess_2000/m0.13z02.hrd\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        line1 = lines[0].replace(\" (\",\"_(\").replace(\"log g\",\"logg\").\\\n",
    "                replace(\"#\",\"\").replace(\"_(Lo)\",\"/Ls\").replace(\"age_\",\"log_t\").\\\n",
    "                split()\n",
    "        line2 = lines[1].replace(\" (\",\"_(\").replace(\"log g\",\"logg\").\\\n",
    "                replace(\"#\",\"\").replace(\"_(Mo)\",\"/Ms\").split()\n",
    "\n",
    "        colnames = line1 + line2\n",
    "        colnames[0::2] = line1\n",
    "        colnames[1::2] = line2\n",
    "\n",
    "        files = glob.glob(path+\"siess_2000/*.hrd\")\n",
    "        for file in files:\n",
    "            try:\n",
    "                data = numpy.concatenate((data, numpy.loadtxt(file)))\n",
    "            except:\n",
    "                data = numpy.loadtxt(file)\n",
    "\n",
    "        # Fix the stellar luminosity.\n",
    "\n",
    "        data[:,2] = numpy.log10(data[:,2])\n",
    "        data[:,-1] = numpy.log10(data[:,-1])\n",
    "    elif tracks == \"Dotter2008\":\n",
    "        f = open(path+\"dotter2008/m200fehp00afep0.trk\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        # Get the column names.\n",
    "\n",
    "        colnames = ['M/Ms'] + lines[1].replace(\"Log \",\"Log\").\\\n",
    "                replace(\"Age \",\"log_t\").replace(\"LogT\",\"Teff\").\\\n",
    "                replace(\"LogL\",\"L/Ls\").replace(\"yrs\",\"yr\").split()[1:]\n",
    "\n",
    "        # Now read in the data files.\n",
    "\n",
    "        files = glob.glob(path+\"dotter2008/*.trk\")\n",
    "        for file in files:\n",
    "            new_data = numpy.loadtxt(file)\n",
    "\n",
    "            # add a column with the mass of the star.\n",
    "\n",
    "            mass = float(file.split(\"/\")[-1][1:4])/100.\n",
    "            mass_arr = numpy.zeros((new_data.shape[0],1)) + mass\n",
    "            new_data = numpy.hstack((mass_arr, new_data))\n",
    "\n",
    "            # Merge with existing data.\n",
    "\n",
    "            try:\n",
    "                data = numpy.concatenate((data, new_data))\n",
    "            except:\n",
    "                data = new_data.copy()\n",
    "\n",
    "        # Get rid of ages more than ~50Myr.\n",
    "\n",
    "        good = data[:,1] < 50.0e6\n",
    "        data = data[good,:]\n",
    "\n",
    "        # Fix some of the columns.\n",
    "\n",
    "        data[:,1] = numpy.log10(data[:,1])\n",
    "        data[:,2] = 10.**data[:,2]\n",
    "\n",
    "    elif tracks == \"Tognelli2011\":\n",
    "        f = open(path+\"tognelli2011/Z0.02000_Y0.2700_XD2E5_ML1.68_AS05/\"\n",
    "                \"TRK_M0.20_Z0.02000_Y0.2700_XD2E5_ML1.68_AS05.DAT\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        # Get the column names.\n",
    "\n",
    "        colnames = ['M/Ms'] + lines[3].replace(\"LOG \",\"LOG_\").\\\n",
    "                replace(\"LOG_AGE\",\"log_t(yr)\").replace(\"LOG_L\",\"L/Ls\").\\\n",
    "                replace(\"LOG_TE\",\"Teff\").split()[1:]\n",
    "\n",
    "        # Now read in the data files.\n",
    "\n",
    "        files = glob.glob(path+\"tognelli2011/\"\n",
    "                \"Z0.02000_Y0.2700_XD2E5_ML1.68_AS05/*.DAT\")\n",
    "        for file in files:\n",
    "            new_data = numpy.loadtxt(file)\n",
    "\n",
    "            # add a column with the mass of the star.\n",
    "\n",
    "            mass = float(file.split(\"/\")[-1].split(\"_\")[1][1:])\n",
    "            mass_arr = numpy.zeros((new_data.shape[0],1)) + mass\n",
    "            new_data = numpy.hstack((mass_arr, new_data))\n",
    "\n",
    "            # Merge with existing data.\n",
    "\n",
    "            try:\n",
    "                data = numpy.concatenate((data, new_data))\n",
    "            except:\n",
    "                data = new_data.copy()\n",
    "\n",
    "        # Fix some of the columns.\n",
    "\n",
    "        data[:,5] = 10.**data[:,5]\n",
    "\n",
    "    elif tracks == \"Feiden2016\":\n",
    "        f = open(path+\"feiden2016/std/\"\n",
    "                \"m0090_GS98_p000_p0_y28_mlt1.884.trk\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        # Get the column names.\n",
    "\n",
    "        colnames = ['M/Ms'] + lines[3].replace(\"Log \",\"Log\").\\\n",
    "                replace(\"Age \",\"log_t\").replace(\"LogT\",\"Teff\").\\\n",
    "                replace(\"LogL\",\"L/Ls\").replace(\"yrs\",\"yr\").split()[1:6]\n",
    "\n",
    "        # Now read in the data files.\n",
    "\n",
    "        files = glob.glob(path+\"feiden2016/std/*.trk\")\n",
    "        for file in files:\n",
    "            new_data = numpy.loadtxt(file, usecols=(0,1,2,3,4))\n",
    "\n",
    "            # add a column with the mass of the star.\n",
    "\n",
    "            mass = float(file.split(\"/\")[-1][1:5])/1000.\n",
    "            mass_arr = numpy.zeros((new_data.shape[0],1)) + mass\n",
    "            new_data = numpy.hstack((mass_arr, new_data))\n",
    "\n",
    "            # Merge with existing data.\n",
    "\n",
    "            try:\n",
    "                data = numpy.concatenate((data, new_data))\n",
    "            except:\n",
    "                data = new_data.copy()\n",
    "\n",
    "        # Get rid of ages more than ~50Myr.\n",
    "\n",
    "        good = data[:,1] < 50.0e6\n",
    "        data = data[good,:]\n",
    "\n",
    "        # Fix some of the columns.\n",
    "\n",
    "        data[:,1] = numpy.log10(data[:,1])\n",
    "        data[:,2] = 10.**data[:,2]\n",
    "\n",
    "    elif tracks == \"Feiden2016mag\":\n",
    "        f = open(path+\"feiden2016/mag/\"\n",
    "                \"m1700_GS98_p000_p0_y28_mlt1.884_mag08kG.ntrk\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        # Get the column names.\n",
    "\n",
    "        colnames = ['M/Ms'] + lines[8].replace(\"conv. \",\"conv.\").\\\n",
    "                replace(\"AGE\",\"log_t(yr)\").replace(\"log(Teff)\",\"Teff\").\\\n",
    "                replace(\"log(L/Lsun)\",\"L/Ls\").replace(\"Model #\",\"Model#\").\\\n",
    "                replace(\"M He core\",\"M_He_core\").replace(\",\",\"\").split()[1:]\n",
    "\n",
    "        # Now read in the data files.\n",
    "\n",
    "        files = glob.glob(path+\"feiden2016/mag/*.ntrk\")\n",
    "        for file in files:\n",
    "            new_data = numpy.loadtxt(file,usecols=tuple([i for i in range(12)]))\n",
    "\n",
    "            # add a column with the mass of the star.\n",
    "\n",
    "            mass = float(file.split(\"/\")[-1][1:5])/1000.\n",
    "            mass_arr = numpy.zeros((new_data.shape[0],1)) + mass\n",
    "            new_data = numpy.hstack((mass_arr, new_data))\n",
    "\n",
    "            # Merge with existing data.\n",
    "\n",
    "            try:\n",
    "                data = numpy.concatenate((data, new_data))\n",
    "            except:\n",
    "                data = new_data.copy()\n",
    "\n",
    "        # Fix some of the columns.\n",
    "\n",
    "        data[:,3] = numpy.log10(data[:,3]*1.0e9)\n",
    "        data[:,7] = 10.**data[:,7]\n",
    "\n",
    "    elif tracks == \"Chen2014\":\n",
    "        f = open(path+\"bressan2012/Z0.017Y0.279/\"\n",
    "                \"Z0.017Y0.279OUTA1.77_F7_M000.700.DAT\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        # Get the column names.\n",
    "\n",
    "        colnames = lines[0].replace(\"LOG \",\"LOG_\").\\\n",
    "                replace(\"AGE\",\"log_t(yr)\").replace(\"LOG_L\",\"L/Ls\").\\\n",
    "                replace(\"LOG_TE\",\"Teff\").replace(\"MASS\",\"M/Ms\").split()\n",
    "\n",
    "        # Now read in the data files.\n",
    "\n",
    "        files = glob.glob(path+\"bressan2012/Z0.017Y0.279/*.DAT\")\n",
    "\n",
    "        for file in files:\n",
    "            new_data = numpy.loadtxt(file, skiprows=2)\n",
    "\n",
    "            # Merge with existing data.\n",
    "\n",
    "            try:\n",
    "                data = numpy.concatenate((data, new_data))\n",
    "            except:\n",
    "                data = new_data.copy()\n",
    "\n",
    "        # Get rid of ages more than ~50Myr.\n",
    "\n",
    "        good = data[:,2] < 50.0e6\n",
    "        data = data[good,:]\n",
    "\n",
    "        # Fix some of the columns.\n",
    "\n",
    "        data[:,2] = numpy.log10(data[:,2])\n",
    "        data[:,4] = 10.**data[:,4]\n",
    "\n",
    "    elif tracks == \"Bressan2012\":\n",
    "        f = open(path+\"bressan2012/bressan2012.dat\")\n",
    "        lines = f.readlines()\n",
    "        f.close()\n",
    "\n",
    "        # Get the column names.\n",
    "\n",
    "        colnames = lines[13].replace(\"log(age/yr)\",\"log_t(yr)\").\\\n",
    "                replace(\"logL/Lo\",\"L/Ls\").replace(\"logTe\",\"Teff\").\\\n",
    "                replace(\"M_act\",\"M/Ms\").split()[1:]\n",
    "\n",
    "        # Now read in the data files.\n",
    "\n",
    "        data = numpy.loadtxt(path+\"bressan2012/bressan2012.dat\")\n",
    "\n",
    "        # Fix some of the columns.\n",
    "\n",
    "        data[:,5] = 10.**data[:,5]\n",
    "\n",
    "    # Make the data into a table.\n",
    "\n",
    "    table = astropy.table.Table(data, names=colnames)\n",
    "\n",
    "    # Return the table now.\n",
    "\n",
    "    return table\n",
    "\n",
    "\n",
    "def pms_get_mstar(age=None, luminosity=None, tracks=\"BHAC15\"):\n",
    "\n",
    "    # Load in the data for the appropriate set of evolutionary tracks.\n",
    "\n",
    "    table = read_pms_data(tracks=tracks)\n",
    "\n",
    "    # Now do the 2D interpolation.\n",
    "\n",
    "    Mstar = scipy.interpolate.LinearNDInterpolator((table[\"L/Ls\"], \\\n",
    "            table[\"log_t(yr)\"]), table[\"M/Ms\"], rescale=True)\n",
    "\n",
    "    # Finally, get the stellar mass.\n",
    "\n",
    "    if isinstance(age,float) and isinstance(luminosity,float):\n",
    "        xi = numpy.array([[luminosity, numpy.log10(age)]])\n",
    "    elif isinstance(age,float):\n",
    "        xi = numpy.array([[luminosity[i],numpy.log10(age)] for i in range(len(luminosity))])\n",
    "    else:    \n",
    "        xi = numpy.array([[luminosity[i],numpy.log10(age[i])] for i in \\\n",
    "                range(len(age))])\n",
    "\n",
    "    return Mstar(xi)\n",
    "\n",
    "def pms_get_teff(luminosity = None, age=1.0e6, tracks=\"BHAC15\"):\n",
    "\n",
    "    # Load in the data for the appropriate set of evolutionary tracks.\n",
    "\n",
    "    table = read_pms_data(tracks=tracks)\n",
    "\n",
    "    # Now do the 2D interpolation.\n",
    "\n",
    "    Teff = scipy.interpolate.LinearNDInterpolator((table[\"L/Ls\"], \\\n",
    "            table[\"log_t(yr)\"]), table[\"Teff\"])\n",
    "\n",
    "    # Finally, get the stellar mass.\n",
    "\n",
    "    if isinstance(age,float) and isinstance(luminosity,float):\n",
    "        xi = numpy.array([[luminosity, numpy.log10(age)]])\n",
    "    elif isinstance(age,float):\n",
    "        xi = numpy.array([[luminosity[i],numpy.log10(age)] for i in range(len(mass))])\n",
    "    else:\n",
    "        xi = numpy.array([[luminosity[i],numpy.log10(age[i])] for i in range(len(age))])\n",
    "\n",
    "    return Teff(xi)\n",
    "\n",
    "def pdspy_get_teff(mass=1.0, age=1.0e6, tracks=\"BHAC15\"):\n",
    "\n",
    "    # Load in the data for the appropriate set of evolutionary tracks.\n",
    "\n",
    "    table = read_pms_data(tracks=tracks)\n",
    "\n",
    "    # Now do the 2D interpolation.\n",
    "\n",
    "    Teff = scipy.interpolate.LinearNDInterpolator((table[\"M/Ms\"], \\\n",
    "            table[\"log_t(yr)\"]), table[\"Teff\"])\n",
    "\n",
    "    # Finally, get the stellar mass.\n",
    "    \n",
    "    if isinstance(age,float) and isinstance(mass,float):\n",
    "        xi = numpy.array([[mass, numpy.log10(age)]])\n",
    "    elif isinstance(age,float):\n",
    "        xi = numpy.array([[mass[i],numpy.log10(age)] for i in range(len(mass))])\n",
    "    else:\n",
    "        xi = numpy.array([[mass,numpy.log10(age[i])] for i in range(len(age))])\n",
    "\n",
    "    return Teff(xi)\n",
    "\n",
    "def pdspy_get_luminosity(mass=1.0, age=1.0e6, tracks=\"BHAC15\"):\n",
    "\n",
    "    # Load in the data for the appropriate set of evolutionary tracks.\n",
    "\n",
    "    table = read_pms_data(tracks=tracks)\n",
    "\n",
    "    # Now do the 2D interpolation.\n",
    "\n",
    "    Lstar = scipy.interpolate.LinearNDInterpolator((table[\"M/Ms\"],\\\n",
    "            table[\"log_t(yr)\"]), table[\"L/Ls\"])\n",
    "\n",
    "    # Finally, get the stellar mass.\n",
    "    print('test')\n",
    "    if isinstance(age,float) and isinstance(mass,float):\n",
    "        xi = numpy.array([[mass, numpy.log10(age)]])\n",
    "    elif isinstance(age,float):\n",
    "        xi = numpy.array([[mass[i],numpy.log10(age)] for i in range(len(mass))])\n",
    "    else:\n",
    "        xi = numpy.array([[mass,numpy.log10(age[i])] for i in range(len(age))])\n",
    "    print('test_end')\n",
    "    return 10.**Lstar(xi)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e7e8dc",
   "metadata": {},
   "source": [
    "# Monte Carlo method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "153baf24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(flux=5.6e-6, std=0.1*5.6e-6, D=0.4, start_index=21):\n",
    "    rng = random.default_rng(start_index)#\n",
    "    b = rng.normal(-2.66, 0.06, 1000)\n",
    "    m = rng.normal(0.91, 0.06, 1000)\n",
    "#     b = random.normal(-2.66, 0.06, 1000)\n",
    "#     m = random.normal(0.91, 0.06, 1000)\n",
    "    flux_al = rng.normal(flux, std, 1000)\n",
    "    L_bol_al = []\n",
    "\n",
    "    lum = flux_al * (D**2)\n",
    "    for i in range(1000):\n",
    "        L_bol_al.append((np.log10(lum[i]) - b[i])/m[i])\n",
    "    L_bol_mean = statistics.mean(L_bol_al)\n",
    "    L_bol_std = statistics.stdev(L_bol_al)\n",
    "    return L_bol_al, L_bol_mean, L_bol_std\n",
    "    \n",
    "def plot_hist(flux, arr, mean, typ='exponent'):\n",
    "    N, bins, patches = plt.hist(arr, bins=100)\n",
    "    max_index = np.argmax(N)\n",
    "    max_value = bins[max_index]\n",
    "\n",
    "    fracs = N / N.max()\n",
    "    norm = colors.Normalize(fracs.min(), fracs.max())\n",
    "\n",
    "    for thisfrac, thispatch in zip(fracs, patches):\n",
    "        color = plt.cm.viridis(norm(thisfrac))\n",
    "        thispatch.set_facecolor(color)\n",
    "    plt.axvline(mean, color='r', linestyle='dashed', linewidth=1, label = 'average')\n",
    "    plt.axvline(max_value, color='b', linestyle='dashed', linewidth=1, label = 'most frequent')\n",
    "    plt.legend()\n",
    "    if typ =='exponent':\n",
    "        plt.xlabel('exponent of L_bol')\n",
    "        plt.ylabel('frequency')\n",
    "        print(f'most frequent result for {flux} mJy is: {max_value}')\n",
    "    elif typ =='mass':\n",
    "        plt.xlabel('mass of the object')\n",
    "        plt.ylabel('frequency')\n",
    "        print(f'most frequent result for {flux} mJy is: {max_value} solar mass')\n",
    "    return max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7bef7cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_flux(flux, lam_in, lam_out, exp=-0.1):\n",
    "    f_in = 3.0e8/lam_in\n",
    "    f_out = 3.0e8/lam_out\n",
    "    return flux*(f_out/f_in)**(exp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22fad456",
   "metadata": {},
   "source": [
    "# Save mass distribution as .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fc0e8cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mass_distribution_table(data, file_name, direc):\n",
    "    \n",
    "    trac = [\"BHAC15\",\"Siess2000\",  \"Dotter2008\", \"Tognelli2011\",\"Feiden2016\",\"Feiden2016mag\",\"Chen2014\",\"Bressan2012\"]\n",
    "\n",
    "    mass_table = pd.DataFrame({trac[i]: data[i]  for i in range(8)})\n",
    "    os.makedirs(direc, exist_ok=True)  \n",
    "    mass_table.to_csv(os.path.join(direc, f'{file_name}.csv'))\n",
    "    return mass_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8eb60fb",
   "metadata": {},
   "source": [
    "# Read mass distribution .csv file as tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "07f66419",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mass(obj, direc='./data_result/mass_table'):\n",
    "    # return: mass table for 4 conditions per each given source. First layer: per conditions: mass distribution for all tracks as a DataFrame\n",
    "    conditions = ['prop056_1myr', 'propn1_1myr', 'prop056_05myr','propn1_05myr']\n",
    "    trac = [\"BHAC15\",\"Siess2000\",  \"Dotter2008\", \"Tognelli2011\",\"Feiden2016\",\"Feiden2016mag\",\"Chen2014\",\"Bressan2012\"]\n",
    "\n",
    "    mass_one_source = []\n",
    "    \n",
    "    for condition in conditions:\n",
    "        mass_one_condi = []\n",
    "        df = pd.read_csv(os.path.join(direc,f'{obj[\"name\"]}_mass_table_{condition}.csv'))\n",
    "        for track in trac:\n",
    "            mass_one_condi.append(df[track].to_numpy())\n",
    "        mass_one_source.append(mass_one_condi)\n",
    "    \n",
    "    return mass_one_source"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a77fde8",
   "metadata": {},
   "source": [
    "# Violin Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bcba56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_axis_style(ax, labels):\n",
    "#     ax.xaxis.set_tick_params(direction='out')\n",
    "    ax.xaxis.set_ticks_position('bottom')\n",
    "    ax.set_xticks(np.arange(1, len(labels) + 1))\n",
    "    ax.set_xticklabels(labels, rotation=45, ha='right', rotation_mode='anchor')\n",
    "    ax.set_xlim(0.25, len(labels) + 0.75)\n",
    "    ax.set_xlabel('Evolutionary Tracks', fontsize=16)\n",
    "    \n",
    "def set_arrows(ax, sources, labels, arrow_offset):\n",
    "    x_arrows = np.arange(1, len(labels) + 1)\n",
    "    y_arrows = []\n",
    "    for i in range(len(labels)): \n",
    "        y_arrow = min(sources[i]) + arrow_offset\n",
    "#         y_arrow = np.percentile(sources[i], 0.00001) - 0.09  #0.0055 for ngVLA  0.09 for first; \n",
    "        y_arrows.append(y_arrow)\n",
    "    y_arrows = np.array(y_arrows)\n",
    "    ax.plot(x_arrows, y_arrows, \"v\", markersize=13, c='#1f77b4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f05f3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# per source\n",
    "def plot_violin(mass_1y_e056, mass_1y_en01, mass_05y_e056, mass_05y_en01, name):\n",
    "    fig, ((ax1,ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(15,10), sharey=True)\n",
    "    ax1.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    ax1.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "    ax1.violinplot(mass_1y_e056)\n",
    "    ax2.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    ax2.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "    ax2.violinplot(mass_1y_en01)\n",
    "    ax3.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    ax3.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "    ax3.violinplot(mass_05y_e056)\n",
    "    ax4.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    ax4.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "    ax4.violinplot(mass_05y_en01)\n",
    "\n",
    "    labels = [\"BHAC15\",\"Siess2000\",  \"Dotter2008\", \"Tognelli2011\",\"Feiden2016\",\"Feiden2016mag\",\"Chen2014\",\"Bressan2012\"]\n",
    "    for ax, mass in zip([ax1, ax2, ax3, ax4], [mass_1y_e056, mass_1y_en01, mass_05y_e056, mass_05y_en01]):\n",
    "        set_axis_style(ax, labels)\n",
    "        set_arrow(ax, mass, labels)\n",
    "    fig.tight_layout()\n",
    "    direc = 'pictures_violin'\n",
    "    os.makedirs(direc, exist_ok=True)\n",
    "    plt.savefig(os.path.join(direc, f'{name}_violin_plot.pdf'))\n",
    "    plt.close()\n",
    "    \n",
    "def plot_violin_dropna(mass_1y_e056, mass_1y_en01, mass_05y_e056, mass_05y_en01, name):\n",
    "#     labels = [\"BHAC15\",\"Siess2000\",  \"Dotter2008\", \"Tognelli2011\",\"Feiden2016\",\"Feiden2016mag\",\"Chen2014\",\"Bressan2012\"]\n",
    "    labels = [\"Baraffe et al., 2015\",\"Siess et al., 2000\",  \"Dotter et al., 2008\", \"Tognelli et al., 2011\",\"Feiden et al., 2016\",\"Feiden et al., 2016, mag\",\"Chen et al., 2014\",\"Bressan et al., 2012\"]\n",
    "\n",
    "    mass_1y_e056 = np.array(mass_1y_e056)\n",
    "    mass_1y_en01 = np.array(mass_1y_en01)\n",
    "    mass_05y_e056 = np.array(mass_05y_e056)\n",
    "    mass_05y_en01 = np.array(mass_05y_en01)\n",
    "    \n",
    "    fig, ((ax1,ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(15,10), sharey=True)\n",
    "\n",
    "    \n",
    "\n",
    "    for mass, ax in zip(np.array([mass_1y_e056,mass_1y_en01, mass_05y_e056, mass_05y_en01,]), np.array([ax1, ax2, ax3, ax4])):    \n",
    "        mass_dropna = []\n",
    "        for i in range(len(labels)):        \n",
    "            if np.isnan(mass[i]).all():\n",
    "                mass_dropna.append(mass[i])\n",
    "            elif np.isnan(mass[i]).any():\n",
    "                mass_dropna.append(mass[i][~np.isnan(mass[i])])\n",
    "            else:\n",
    "                mass_dropna.append(mass[i])\n",
    "        ax.violinplot(mass_dropna)\n",
    "\n",
    "    ax1.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    ax1.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "   \n",
    "\n",
    "    ax2.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    ax2.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "        \n",
    "        \n",
    "    ax3.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    ax3.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "\n",
    "        \n",
    "        \n",
    "    ax4.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    ax4.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "\n",
    "\n",
    "    for ax in [ax1, ax2, ax3, ax4]:\n",
    "        set_axis_style(ax, labels)\n",
    "    fig.tight_layout()\n",
    "    direc = 'pictures_violin/dropna'\n",
    "    os.makedirs(direc, exist_ok=True)\n",
    "    plt.savefig(os.path.join(direc, f'{name}_violin_plot_dropna.pdf'))\n",
    "    plt.close()\n",
    "    \n",
    "    \n",
    "def plot_violin_dropna_with_arrow(mass_1y_e056, mass_1y_en01, mass_05y_e056, mass_05y_en01, name, arrow_offset, save_direc):\n",
    "#     labels = [\"BHAC15\",\"Siess2000\",  \"Dotter2008\", \"Tognelli2011\",\"Feiden2016\",\"Feiden2016mag\",\"Chen2014\",\"Bressan2012\"]\n",
    "    labels = [\"Baraffe et al., 2015\",\"Siess et al., 2000\",  \"Dotter et al., 2008\", \"Tognelli et al., 2011\",\"Feiden et al., 2016\",\"Feiden et al., 2016, mag\",\"Chen et al., 2014\",\"Bressan et al., 2012\"]\n",
    "\n",
    "    mass_1y_e056 = np.array(mass_1y_e056)\n",
    "    mass_1y_en01 = np.array(mass_1y_en01)\n",
    "    mass_05y_e056 = np.array(mass_05y_e056)\n",
    "    mass_05y_en01 = np.array(mass_05y_en01)\n",
    "    \n",
    "    fig, ((ax1,ax2), (ax3, ax4)) = plt.subplots(nrows=2, ncols=2, figsize=(15,10), sharey=True)\n",
    "\n",
    "    \n",
    "\n",
    "    for mass, ax in zip(np.array([mass_1y_e056,mass_1y_en01, mass_05y_e056, mass_05y_en01,]), np.array([ax1, ax2, ax3, ax4])):    \n",
    "        mass_dropna = []\n",
    "        for i in range(len(labels)):        \n",
    "            if np.isnan(mass[i]).all():\n",
    "                mass_dropna.append(mass[i])\n",
    "            elif np.isnan(mass[i]).any():\n",
    "                mass_dropna.append(mass[i][~np.isnan(mass[i])])\n",
    "            else:\n",
    "                mass_dropna.append(mass[i])\n",
    "        ax.violinplot(mass_dropna)\n",
    "        set_arrows(ax, mass_dropna, labels, arrow_offset)\n",
    "\n",
    "    ax1.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    ax1.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "   \n",
    "\n",
    "    ax2.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    ax2.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "        \n",
    "        \n",
    "    ax3.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    ax3.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "\n",
    "        \n",
    "        \n",
    "    ax4.set_title(f'{name}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    ax4.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "\n",
    "\n",
    "    for ax, mass in zip([ax1, ax2, ax3, ax4], [mass_1y_e056, mass_1y_en01, mass_05y_e056, mass_05y_en01]):\n",
    "        set_axis_style(ax, labels)\n",
    "#         set_arrows(ax, mass, labels)\n",
    "    fig.tight_layout()\n",
    "    direc = save_direc\n",
    "    os.makedirs(direc, exist_ok=True)\n",
    "    plt.savefig(os.path.join(direc, f'{name}_violin_plot.pdf'))\n",
    "    plt.close()\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c0643162",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all sources under the same track and conditions\n",
    "def plot_violin_same_track(mass_all_sources, trackname, track_label, condition, labels, color=False, dropna=True):\n",
    "    fig, axs = plt.subplots(1,1, figsize=(10,5))\n",
    "    axs.violinplot(mass_all_sources)\n",
    "    axs.set_ylabel('$M_*$ (M$_{\\odot}$)', fontsize=16)\n",
    "    \n",
    "    if condition == 'prop056_1myr':\n",
    "        plt.title(f'{track_label}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    elif condition == 'prop056_05myr':\n",
    "        plt.title(f'{track_label}'+ r\", $L_{bol} \\propto \\nu^{0.56}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    elif condition == 'propn1_1myr':\n",
    "        plt.title(f'{track_label}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 1 $Myr$\", fontsize=20)\n",
    "    elif condition == 'propn1_05myr':\n",
    "        plt.title(f'{track_label}'+ r\", $L_{bol} \\propto \\nu^{-0.1}$\" + r\", 0.5 $Myr$\", fontsize=20)\n",
    "    else:\n",
    "        raise Exception(\"Illegal filename\")\n",
    "    set_axis_style(axs, labels)\n",
    "    axs.set_xlabel('Sources', fontsize=16)\n",
    "\n",
    "    if dropna:\n",
    "        direc = 'pictures_violin/same_track'\n",
    "        os.makedirs(direc, exist_ok=True)\n",
    "        plt.savefig(os.path.join(direc, f'{trackname}_{condition}_dropna_violin_plot.pdf'), bbox_inches='tight')\n",
    "    else:\n",
    "        direc = 'pictures_violin/same_track'\n",
    "        os.makedirs(direc, exist_ok=True)\n",
    "        plt.savefig(os.path.join(direc, f'{trackname}_{condition}_violin_plot.pdf'), bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "def read_plot_violin_same_track(objs, trackname='BHAC15',track_label=\"Baraffe et al., 2015\", direc='./data_result/mass_table', dropna=True):     \n",
    "# read mass data from previous calculation\n",
    "    conditions = ['prop056_1myr', 'prop056_05myr', 'propn1_1myr', 'propn1_05myr']\n",
    "\n",
    "    for condition in conditions:\n",
    "        mass_all_sources_same_track = []\n",
    "        labels = []\n",
    "        for obj in objs:\n",
    "            df = pd.read_csv(os.path.join(direc,f'{obj[\"name\"]}_mass_table_{condition}.csv'))\n",
    "            if dropna:\n",
    "                if np.isnan(df[trackname]).all():\n",
    "                    mass_all_sources_same_track.append(df[trackname])\n",
    "                elif np.isnan(df[trackname]).any():\n",
    "                    mass_all_sources_same_track.append(df[trackname][~np.isnan(df[trackname])])\n",
    "                else:\n",
    "                    mass_all_sources_same_track.append(df[trackname])\n",
    "            else: \n",
    "                mass_all_sources_same_track.append(df[trackname])\n",
    "            labels.append(obj['name'])\n",
    "        plot_violin_same_track(mass_all_sources_same_track, trackname,track_label, condition, labels, dropna)\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01eb4efa",
   "metadata": {},
   "source": [
    "# Main calcualtion process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8d7349cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Disks information in dictionary \\n# Measured in Summer 2021\\nobj_56 = {'name': 'HOPS-56', 'frequency': 33.0e9, 'flux':5.69e-5}   #3.07478e-5\\nobj_65 = {'name': 'HOPS-65', 'frequency': 15.0e9, 'flux':1.064e-5}  #9.334 e-6\\nobj_124 = {'name': 'HOPS-124', 'frequency': 44.0e9, 'flux': 0.0005424}  #0.000591628 Jy\\nobj_140 = {'name': 'HOPS-140', 'frequency': 33.0e9, 'flux':0.0001537}   #no such source\\nobj_157_a = {'name': 'HOPS-157_a', 'frequency': 33.0e9, 'flux':2.67e-5}   #4.09e-5\\nobj_157_b = {'name': 'HOPS-157_b', 'frequency': 33.0e9, 'flux':2.34e-5}   #3.70e-6\\nobj_163_3RMS = {'name': 'HOPS-163_3RMS', 'frequency': 33.0e9, 'flux':4.87e-6*3}  #4.87e-6\\nobj_270_3RMS = {'name': 'HH270MMS2_3RMS', 'frequency': 44.0e9, 'flux':8.75e-6*3} # 9.0919e-6\\n\\nobj_56_3RMS = {'name': 'HOPS-56_3RMS', 'frequency': 33.0e9, 'flux':7.81e-6*3} #5.02e-6\\nobj_65_3RMS = {'name': 'HOPS-65_3RMS', 'frequency': 15.0e9, 'flux':2.44e-6*3} #2.46e-6\\nobj_124_3RMS = {'name': 'HOPS-124_3RMS', 'frequency': 44.0e9, 'flux': 6.54e-5*3}  #1.000088e-5\\nobj_140_3RMS = {'name': 'HOPS-140_3RMS', 'frequency': 33.0e9, 'flux':7.54e-6*3}   # 5.014e-6\\nobj_157_3RMS = {'name': 'HOPS-157_3RMS', 'frequency': 33.0e9, 'flux':9.49e-6*3}   #4.96e-6\\n\\n\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# Disks information in dictionary \n",
    "# Measured in Summer 2021\n",
    "obj_56 = {'name': 'HOPS-56', 'frequency': 33.0e9, 'flux':5.69e-5}   #3.07478e-5\n",
    "obj_65 = {'name': 'HOPS-65', 'frequency': 15.0e9, 'flux':1.064e-5}  #9.334 e-6\n",
    "obj_124 = {'name': 'HOPS-124', 'frequency': 44.0e9, 'flux': 0.0005424}  #0.000591628 Jy\n",
    "obj_140 = {'name': 'HOPS-140', 'frequency': 33.0e9, 'flux':0.0001537}   #no such source\n",
    "obj_157_a = {'name': 'HOPS-157_a', 'frequency': 33.0e9, 'flux':2.67e-5}   #4.09e-5\n",
    "obj_157_b = {'name': 'HOPS-157_b', 'frequency': 33.0e9, 'flux':2.34e-5}   #3.70e-6\n",
    "obj_163_3RMS = {'name': 'HOPS-163_3RMS', 'frequency': 33.0e9, 'flux':4.87e-6*3}  #4.87e-6\n",
    "obj_270_3RMS = {'name': 'HH270MMS2_3RMS', 'frequency': 44.0e9, 'flux':8.75e-6*3} # 9.0919e-6\n",
    "\n",
    "obj_56_3RMS = {'name': 'HOPS-56_3RMS', 'frequency': 33.0e9, 'flux':7.81e-6*3} #5.02e-6\n",
    "obj_65_3RMS = {'name': 'HOPS-65_3RMS', 'frequency': 15.0e9, 'flux':2.44e-6*3} #2.46e-6\n",
    "obj_124_3RMS = {'name': 'HOPS-124_3RMS', 'frequency': 44.0e9, 'flux': 6.54e-5*3}  #1.000088e-5\n",
    "obj_140_3RMS = {'name': 'HOPS-140_3RMS', 'frequency': 33.0e9, 'flux':7.54e-6*3}   # 5.014e-6\n",
    "obj_157_3RMS = {'name': 'HOPS-157_3RMS', 'frequency': 33.0e9, 'flux':9.49e-6*3}   #4.96e-6\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "059caa38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOPS-157 primary, mean:  3.929035714285714e-05\n",
      "HOPS-157 primary, std:  1.0122337691724482e-05\n",
      "HOPS-157 secondary, mean:  4.5862535e-06\n",
      "HOPS-157 secondary, std:  2.3142691686638176e-06\n"
     ]
    }
   ],
   "source": [
    "# find mean and std for HOPS-157 (with 6 measurements)\n",
    "HOPS_157_a = [3.5776e-5, 5.03559e-5, 4.5326e-5, 5.48484e-5, 2.67083e-5, 2.89496e-5, 3.30683e-5]\n",
    "HOPS_157_b = [7.27462e-6, 7.98252e-6, 1.515971e-6, 2.8801e-6, 4.23201e-6, 3.6323e-6]\n",
    "HOPS_157_a_mean = np.mean(HOPS_157_a)\n",
    "HOPS_157_b_mean = np.mean(HOPS_157_b)\n",
    "HOPS_157_a_std = np.std(HOPS_157_a)\n",
    "HOPS_157_b_std = np.std(HOPS_157_b)\n",
    "print('HOPS-157 primary, mean: ', HOPS_157_a_mean)\n",
    "print('HOPS-157 primary, std: ', HOPS_157_a_std)\n",
    "print('HOPS-157 secondary, mean: ', HOPS_157_b_mean)\n",
    "print('HOPS-157 secondary, std: ', HOPS_157_b_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a66f867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4bc389ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disks information in dictionary \n",
    "#update measurement Oct/2022\n",
    "\n",
    "# with central source:\n",
    "obj_56 = {'name': 'HOPS-56', 'frequency': 33.0e9, 'flux':3.17348e-5, 'std': 0.1 * 3.17348e-5, 'arrow_offset': -0.06} #checked  \n",
    "obj_65 = {'name': 'HOPS-65', 'frequency': 15.0e9, 'flux':8.615e-6, 'std': 0.1 * 8.615e-6 , 'arrow_offset': -0.03}  #checked\n",
    "obj_124 = {'name': 'HOPS-124', 'frequency': 44.0e9, 'flux': 0.000570296, 'std': 0.1 * 0.000570296, 'arrow_offset': -0.13} #checked\n",
    "\n",
    "obj_56_3RMS = {'name': 'HOPS-56_3RMS', 'frequency': 33.0e9, 'flux':4.911e-6*3, 'std': 0.1 * 4.911e-6*3, 'arrow_offset': -0.045} \n",
    "obj_65_3RMS = {'name': 'HOPS-65_3RMS', 'frequency': 15.0e9, 'flux':2.43e-6*3, 'std': 0.1 * 2.43e-6*3, 'arrow_offset': -0.025} \n",
    "obj_124_3RMS = {'name': 'HOPS-124_3RMS', 'frequency': 44.0e9, 'flux': 9.6748*3, 'std': 0.1 * 9.6748*3,'arrow_offset': -11}  \n",
    "obj_157_3RMS = {'name': 'HOPS-157_3RMS', 'frequency': 33.0e9, 'flux':4.933e-6*3, 'std': 0.1 * 4.933e-6*3,'arrow_offset': -0.045}   \n",
    "\n",
    "#no central source\n",
    "obj_157_a = {'name': 'HOPS-157_a', 'frequency': 33.0e9, 'flux':HOPS_157_a_mean, 'std':HOPS_157_a_std, 'arrow_offset': -0.075}   #checked  Vaires 4.5279e-5\n",
    "obj_157_b = {'name': 'HOPS-157_b', 'frequency': 33.0e9, 'flux':HOPS_157_b_mean, 'std':HOPS_157_b_std, 'arrow_offset': -0.015}   #checked  Varies largely 2.017e-6\n",
    "obj_163_3RMS = {'name': 'HOPS-163_3RMS', 'frequency': 33.0e9, 'flux':4.87e-6*3, 'std': 0.1 * 4.87e-6*3, 'arrow_offset': -0.045}  # checked\n",
    "obj_270_3RMS = {'name': 'HH270MMS2_3RMS', 'frequency': 44.0e9, 'flux':9.0872e-6*3, 'std': 0.1 * 9.0872e-6*3, 'arrow_offset': -0.06}  # checked\n",
    "obj_140_3RMS = {'name': 'HOPS-140_3RMS', 'frequency': 33.0e9, 'flux':4.9803e-6*3, 'std': 0.1 * 4.9803e-6*3,'arrow_offset': -0.05}  # checked\n",
    "\n",
    "#ngVLA limit\n",
    "obj_ngVLA = {'name': 'ngVLA', 'frequency': 27.0e9, 'flux':0.23e-6*3, 'std': 0.1 *0.23e-6*3, 'arrow_offset': -0.0055} \n",
    "# cite: https://ngvla.nrao.edu/page/performance. Taking theta 1/2 = 100 mas and 27 GHz continum RMS. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42a938fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Globally used\n",
    "objs = [obj_56, obj_56_3RMS, obj_65, obj_65_3RMS, obj_124,obj_124_3RMS, obj_140_3RMS, obj_157_a, obj_157_b, obj_157_3RMS, obj_163_3RMS, obj_270_3RMS]\n",
    "tracks = [\"BHAC15\",\"Siess2000\",  \"Dotter2008\", \"Tognelli2011\",\"Feiden2016\",\"Feiden2016mag\",\"Chen2014\",\"Bressan2012\"]\n",
    "\n",
    "obj_ngVLAs = [obj_ngVLA]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "098cf160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'ngVLA', 'frequency': 27000000000.0, 'flux': 6.9e-07, 'std': 6.9e-08, 'arrow_offset': -0.0055}\n"
     ]
    }
   ],
   "source": [
    "# main process\n",
    "for obj in obj_ngVLAs:  # change to objs if calculating for targeted disks. \n",
    "# for obj in objs:\n",
    "    print(obj)\n",
    "    \n",
    "    lam_in = 3.0e8/(obj['frequency'])\n",
    "    lam_out = 4.1e-2\n",
    "    fluxin = obj['flux']\n",
    "    flux_std = obj['std']\n",
    "    flux_41_01 = find_flux(fluxin*1000, lam_in, lam_out, -0.1)\n",
    "    flux_41_051 = find_flux(fluxin*1000, lam_in, lam_out, 0.51)\n",
    "\n",
    "    trac = [\"BHAC15\",\"Siess2000\",  \"Dotter2008\", \"Tognelli2011\",\"Feiden2016\",\"Feiden2016mag\",\"Chen2014\",\"Bressan2012\"]\n",
    "\n",
    "    #sample via monte carlo method\n",
    "    start_index = 21\n",
    "    L_bol_056, L_mean_056, L_std_056 = monte_carlo(flux=flux_41_051, std = flux_std, D=0.4, start_index=start_index)\n",
    "    L_bol_n01, L_mean_n01, L_std_n01 = monte_carlo(flux=flux_41_01, std = flux_std, D=0.4, start_index=start_index)\n",
    "\n",
    "    #calculate mass distribution\n",
    "    mass_al_trac_1y = np.empty(len(trac), dtype=object)\n",
    "    mass_al_trac_1yn = np.empty(len(trac), dtype=object)\n",
    "    mass_al_trac_05y = np.empty(len(trac), dtype=object)\n",
    "    mass_al_trac_05yn = np.empty(len(trac), dtype=object)\n",
    "\n",
    "    for track in trac: \n",
    "        mass_al_trac_1y[trac.index(track)] = pms_get_mstar(age = 1.0e6, luminosity= L_bol_056, tracks=track)\n",
    "        mass_al_trac_1yn[trac.index(track)] = pms_get_mstar(age = 1.0e6, luminosity= L_bol_n01, tracks=track)\n",
    "        mass_al_trac_05y[trac.index(track)] = pms_get_mstar(age = 0.5e6, luminosity=L_bol_056, tracks=track)\n",
    "        mass_al_trac_05yn[trac.index(track)] = pms_get_mstar(age = 0.5e6, luminosity= L_bol_n01, tracks=track)\n",
    "\n",
    "    # generate violin plot\n",
    "#     plot_violin(mass_al_trac_1y, mass_al_trac_1yn, mass_al_trac_05y, mass_al_trac_05yn, obj['name'])\n",
    "    plot_violin_dropna(mass_al_trac_1y, mass_al_trac_1yn, mass_al_trac_05y, mass_al_trac_05yn, obj['name'])\n",
    "    # create pandas dataframe and save to csv files\n",
    "    save_mass_distribution_table(mass_al_trac_1y, f'{obj[\"name\"]}_mass_table_prop056_1myr', 'data_result/mass_table')\n",
    "    save_mass_distribution_table(mass_al_trac_1yn, f'{obj[\"name\"]}_mass_table_propn1_1myr', 'data_result/mass_table')\n",
    "    save_mass_distribution_table(mass_al_trac_05y, f'{obj[\"name\"]}_mass_table_prop056_05myr', 'data_result/mass_table')\n",
    "    save_mass_distribution_table(mass_al_trac_05yn, f'{obj[\"name\"]}_mass_table_propn1_05myr', 'data_result/mass_table')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "486aac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mass distribution and plot violin plot per each source under 4 conditions (drop nan values, with arrow):\n",
    "\n",
    "for obj in obj_ngVLAs:\n",
    "\n",
    "    mass_4_condition = read_mass(obj, './data_result/mass_table')\n",
    "    plot_violin_dropna_with_arrow(mass_4_condition[0], mass_4_condition[1], mass_4_condition[2], mass_4_condition[3], obj['name'], obj['arrow_offset'], 'pictures_violin/per_sourse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0a91e53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read mass distribution and plot mass distribution of all sources under the same track and conditions \n",
    "track_labels = [\"Baraffe et al., 2015\",\"Siess et al., 2000\",  \"Dotter et al., 2008\", \"Tognelli et al., 2011\",\"Feiden et al., 2016\",\"Feiden et al., 2016, mag\",\"Chen et al., 2014\",\"Bressan et al., 2012\"]\n",
    "\n",
    "\n",
    "for track, track_name in zip(tracks, track_labels):\n",
    "     read_plot_violin_same_track(objs, track,track_name, dropna=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f2f6e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
